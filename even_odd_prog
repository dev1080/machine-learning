from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# load the dataset
#dataset = pd.read_csv('even_odd.csv')
dataset = np.loadtxt('even_odd.csv', delimiter=',')

# split into input (X) and output (y) variables
#X = dataset.iloc[:,:-1]
#y = dataset.iloc[:,-1]
X = dataset[:,:-1]
y = dataset[:,-1]

X_new = []
y_new = []
n = 7
for i in range(len(X)):
    tmp = str(bin(int(X[i][0]))).replace("0b","").zfill(n)
    tmp1 = []
    for j in tmp:
        tmp1.append(int(j))
    X_new.append(tmp1)
    y_new.append(int(y[i]))

X_new = np.array(X_new)
y_new = np.array(y_new)

# for i in range(len(X_new)):
#     print(X_new[i],y_new[i])

adm = Adam(learning_rate=0.1)

# define the keras model
model = Sequential()
model.add(Dense(7, input_dim=7, activation='relu'))
model.add(Dense(4, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
# compile the keras model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
#mean_squared_error
#binary_crossentropy

# fit the keras model on the dataset
history = model.fit(X_new, y_new,validation_split=0.3,batch_size=1, epochs=100)

#plt.plot(history.history['loss'])
#plt.plot(history.history['val_loss'])
#plt.show()

# # evaluate the keras model
_, accuracy = model.evaluate(X_new, y_new)
print('Accuracy: %.2f' % (accuracy*100))

# # make class predictions with the model
predictions = model.predict(X_new)# predict_classes(X)
#print(predictions)
# # summarize the first 5 cases
for i in range(20):
   print('%s => %f (expected %d)' % (X_new[i].tolist(), predictions[i], y_new[i]))
